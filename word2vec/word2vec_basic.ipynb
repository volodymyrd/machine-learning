{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Investegate data using in this [model](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: /var/folders/zw/_6tnl22d76d6lj6m1ptc_64w0000gn/T/text8.zip\n",
      "file size: 31344016\n",
      "Data size: 17005207\n",
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including', 'the', 'diggers', 'of', 'the', 'english', 'revolution', 'and', 'the', 'sans', 'culottes', 'of', 'the', 'french', 'revolution', 'whilst', 'the', 'term', 'is', 'still', 'used', 'in', 'a', 'pejorative', 'way', 'to', 'describe', 'any', 'act', 'that', 'used', 'violent', 'means', 'to', 'destroy', 'the', 'organization', 'of', 'society', 'it', 'has', 'also', 'been', 'taken', 'up', 'as', 'a', 'positive', 'label', 'by', 'self', 'defined', 'anarchists', 'the', 'word', 'anarchism', 'is', 'derived', 'from', 'the', 'greek', 'without', 'archons', 'ruler', 'chief', 'king', 'anarchism', 'as', 'a', 'political', 'philosophy', 'is', 'the', 'belief', 'that', 'rulers', 'are', 'unnecessary', 'and', 'should', 'be', 'abolished', 'although', 'there', 'are', 'differing']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tempfile import gettempdir\n",
    "from six.moves import urllib\n",
    "\n",
    "# Step 1: Download the data.\n",
    "url = 'http://mattmahoney.net/dc/'\n",
    "filename = 'text8.zip'\n",
    "\n",
    "local_filename = os.path.join(gettempdir(), filename)\n",
    "print(f'File path: {local_filename}')\n",
    "\n",
    "if not os.path.exists(local_filename):\n",
    "    local_filename, _ = urllib.request.urlretrieve(url + filename, local_filename)\n",
    "    \n",
    "statinfo = os.stat(local_filename)\n",
    "print(f'file size: {statinfo.st_size}')\n",
    "\n",
    "# Read the data into a list of strings.\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "\n",
    "with zipfile.ZipFile(local_filename) as f:\n",
    "    vocabulary = tf.compat.as_str(f.read(f.namelist()[0])).split()\n",
    "\n",
    "print(f'Data size: {len(vocabulary)}')\n",
    "print(vocabulary[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words (+UNK) [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]\n",
      "Sample data [5234, 3081, 12, 6, 195, 2, 3134, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Build the dictionary and replace rare words with UNK token.\n",
    "import collections\n",
    "vocabulary_size = 50000\n",
    "def build_dataset(words, n_words):\n",
    "    \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    dictionary = {}\n",
    "    for word, _ in count:\n",
    "      dictionary[word] = len(dictionary)\n",
    "    data = []\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "      index = dictionary.get(word, 0)\n",
    "      if index == 0:  # dictionary['UNK']\n",
    "        unk_count += 1\n",
    "      data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary\n",
    "\n",
    "# Filling 4 global variables:\n",
    "  # data - list of codes (integers from 0 to vocabulary_size-1).\n",
    "  #   This is the original text but words are replaced by their codes\n",
    "  # count - map of words(strings) to count of occurrences\n",
    "  # dictionary - map of words(strings) to their codes(integers)\n",
    "  # reverse_dictionary - maps codes(integers) to words(strings)\n",
    "data, count, unused_dictionary, reverse_dictionary = build_dataset(vocabulary, vocabulary_size)\n",
    "del vocabulary  # Hint to reduce memory.\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data', data[:10], [reverse_dictionary[i] for i in data[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
